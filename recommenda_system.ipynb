{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flo-shi/Recommender-System/blob/master/recommenda_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l9uCbj9JdFDN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats # For statistical functions\n",
        "from sklearn.model_selection import train_test_split # Splitting train and test data\n",
        "from sklearn.metrics.pairwise import cosine_similarity # For user to user similarities\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-FTILIAdFDX"
      },
      "source": [
        "Importing datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "gzweOJzXdFDc",
        "outputId": "8aabbfc8-dc79-4852-f362-ad0db588c99c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\pjr\\\\OneDrive\\\\Documents\\\\data science\\\\Recommender system\\\\archive (1)\\\\Books.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4475eea08a88>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'C:\\Users\\pjr\\OneDrive\\Documents\\data science\\Recommender system\\archive (1)\\Books.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'C:\\Users\\pjr\\OneDrive\\Documents\\data science\\Recommender system\\archive (1)\\Ratings.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'C:\\Users\\pjr\\OneDrive\\Documents\\data science\\Recommender system\\archive (1)\\Users.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\pjr\\\\OneDrive\\\\Documents\\\\data science\\\\Recommender system\\\\archive (1)\\\\Books.csv'"
          ]
        }
      ],
      "source": [
        "df1 = pd.read_csv(r'C:\\Users\\pjr\\OneDrive\\Documents\\data science\\Recommender system\\archive (1)\\Books.csv')\n",
        "df2 = pd.read_csv(r'C:\\Users\\pjr\\OneDrive\\Documents\\data science\\Recommender system\\archive (1)\\Ratings.csv')\n",
        "df3 = pd.read_csv(r'C:\\Users\\pjr\\OneDrive\\Documents\\data science\\Recommender system\\archive (1)\\Users.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m9kbagqeCHV",
        "outputId": "b1a4c4a1-3dbf-4cd3-cb8c-9c32eda91cba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJIlIdridFDg"
      },
      "source": [
        "Understanding this dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc2TczsRdFDh"
      },
      "outputs": [],
      "source": [
        "# df1 Books\n",
        "print(df1.shape) # No of rows and columns\n",
        "df1.head() # First 5 rows in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYLYPUFEdFDj"
      },
      "outputs": [],
      "source": [
        "df1.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1zOko3AdFDk"
      },
      "outputs": [],
      "source": [
        "df1.drop(columns=['Image-URL-S','Image-URL-M','Image-URL-L'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7AIp-TTdFDm"
      },
      "outputs": [],
      "source": [
        "# df2 Ratings\n",
        "print(df2.shape)\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-vFBmo3dFDo"
      },
      "outputs": [],
      "source": [
        "# df3 Users\n",
        "print(df3.shape)\n",
        "df3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOPdLqpxdFDq"
      },
      "outputs": [],
      "source": [
        "df1.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNyQfkUOdFDr"
      },
      "outputs": [],
      "source": [
        "df3.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV1fEdJ8dFDs"
      },
      "source": [
        "Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZLiBS7RdFDt"
      },
      "outputs": [],
      "source": [
        "df1.duplicated() #  Check for duplicates in rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hh3u0tc0dFDu"
      },
      "outputs": [],
      "source": [
        "df2.duplicated()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFhXJ0qjdFDv"
      },
      "outputs": [],
      "source": [
        "df3.duplicated()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhFzGcKKdFDw"
      },
      "outputs": [],
      "source": [
        "df1.nunique().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA0C5l0ddFDx"
      },
      "outputs": [],
      "source": [
        "df1['Year-Of-Publication'] = pd.to_numeric(df1['Year-Of-Publication'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPbHXwdndFDx"
      },
      "outputs": [],
      "source": [
        "# Dealing with null values of df1(Books)\n",
        "df1.isnull().sum().sort_values(ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBVHJ0xIdFDy"
      },
      "outputs": [],
      "source": [
        "# Remove rows with null values\n",
        "df1 = df1.dropna(subset=['Book-Author','Publisher','Year-Of-Publication'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOHyHwIGdFDz"
      },
      "outputs": [],
      "source": [
        "df1.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN_kRrd_dFD0"
      },
      "outputs": [],
      "source": [
        "df2.isnull().sum().sort_values(ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9au2glvBdFD0"
      },
      "outputs": [],
      "source": [
        "df3.isnull().sum().sort_values(ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVRD2vbZdFD1"
      },
      "outputs": [],
      "source": [
        "# Dealing with null values of df3(User's age)\n",
        "df3['Age'].dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ-BAiwHdFD2"
      },
      "source": [
        "Dealing with outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpUGjxNSdFD2"
      },
      "outputs": [],
      "source": [
        "# df3\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.title('boxplot for users ')\n",
        "sns.boxplot(data=df3, x='Age')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILdg2rq4dFD3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.hist(data=df3, x = 'Age')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANsKoigRdFD4"
      },
      "outputs": [],
      "source": [
        "def find_boundaries(data,variable):\n",
        "    # Finding the IQR\n",
        "    Q1 = data[variable].quantile(.25)\n",
        "    Q3 = data[variable].quantile(.75)\n",
        "    IQR = Q3 - Q1\n",
        "    # Finding lower and upper bounadry\n",
        "    l_boundary = Q1 - 1.5 * IQR\n",
        "    u_boundary = Q3 + 1.5 * IQR\n",
        "    return l_boundary, u_boundary\n",
        "\n",
        "l_column , u_column = find_boundaries(df3, 'Age')\n",
        "print(\"Lower boundary is: \", l_column)\n",
        "print(\"Upper boundary is: \", u_column)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDbd7sp1dFD5"
      },
      "outputs": [],
      "source": [
        "remove = np.where(df3['Age'] > 74, True,\n",
        "                  np.where(df3['Age'] < 10, True, False))\n",
        "\n",
        "df3 = df3.loc[~(remove)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "co81JuHwdFD6"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "sns.set_theme(style='darkgrid',palette=\"rocket\")\n",
        "ax =  sns.histplot(data=df3, x= 'Age', kde=True, bins=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_5HPoatdFD6"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(df3['Age'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4cOOXm0dFD7"
      },
      "outputs": [],
      "source": [
        "# df1\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.title('boxplot for Year-Of-Publication ')\n",
        "sns.boxplot(df1['Year-Of-Publication'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pk7gaz6hdFD8"
      },
      "outputs": [],
      "source": [
        "# df1['Year-Of-Publication'].plot(kind='hist')\n",
        "sns.histplot(df1['Year-Of-Publication'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDedLWbYdFD9"
      },
      "outputs": [],
      "source": [
        "lb_column,ub_column = find_boundaries(df1, 'Year-Of-Publication')\n",
        "print(\"Lower boundary is: \", lb_column)\n",
        "print(\"Upper boundary is: \", ub_column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y20z0zTPdFD-"
      },
      "outputs": [],
      "source": [
        "remove_year = np.where(df1['Year-Of-Publication'] < 1972, True,\n",
        "                       np.where(df1['Year-Of-Publication'] > 2016, True, False))\n",
        "df1 = df1.loc[~(remove_year)]\n",
        "\n",
        "# Histogram for year of population\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.set_theme(style='darkgrid')\n",
        "ax = sns.histplot(data=df1, x = 'Year-Of-Publication', kde=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7udLmOaRdFD_"
      },
      "source": [
        "Dealing with categorical data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OECdKYbrdFEA"
      },
      "outputs": [],
      "source": [
        "# Construct new attribute\n",
        "df3['Country'] = df3['Location'].str.extract(r',\\s*([^,]+)$')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkMgtogwdFEA"
      },
      "outputs": [],
      "source": [
        "df3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55sPKY7KdFEB"
      },
      "outputs": [],
      "source": [
        "df3.drop(columns=['Location'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ejg_vmQhdFEC"
      },
      "outputs": [],
      "source": [
        "country_counts = df3['Country'].value_counts()\n",
        "print(country_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgX6k_AGdFEK"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,16))\n",
        "plt.pie(country_counts, labels=country_counts.index, autopct='%1.1f%%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Phx1dA4odFEL"
      },
      "source": [
        "Merging the diferent dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOgNKCu_dFEM"
      },
      "outputs": [],
      "source": [
        "df_merge = pd.merge(df1,df2, on='ISBN', how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03r-OImodFEM"
      },
      "outputs": [],
      "source": [
        "final_df = pd.merge(df_merge, df3, on='User-ID', how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "theNsusddFEN"
      },
      "outputs": [],
      "source": [
        "print(final_df.shape)\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k15-nRgddFEO"
      },
      "outputs": [],
      "source": [
        "# Identifing unique values\n",
        "print(\"The total dataset has \", final_df.shape[0],\" values.\")\n",
        "print(\"The dataset has \", final_df['ISBN'].nunique(), \" books with unique values\")\n",
        "print(\"The dataset has \", final_df['User-ID'].nunique(), \" users with unique values\")\n",
        "print(\"The dataset has \", sorted(final_df['Book-Rating'].unique()), \" ratings.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTv1chmHdFEP"
      },
      "outputs": [],
      "source": [
        "final_df['Book-Rating'].hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l74S60M0dFEP"
      },
      "outputs": [],
      "source": [
        "final_df.isnull().sum().sort_values(ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aREe0p_dFEQ"
      },
      "outputs": [],
      "source": [
        "final_df.dropna(subset=['Age','Country'], inplace=True)\n",
        "print(final_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUpWGewhdFER"
      },
      "outputs": [],
      "source": [
        "author_counts = final_df['Book-Author'].value_counts()\n",
        "print(author_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJZraXwldFES"
      },
      "source": [
        "Transforming categorical data and splitting train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2mV2oOpdFES"
      },
      "outputs": [],
      "source": [
        "# Divide data into training and vlidation subsets\n",
        "x_train, x_test, y_train, y_test = train_test_split(final_df[['Book-Title','User-ID','Book-Author','Publisher','Year-Of-Publication','Book-Rating']]\n",
        "                                                    ,final_df['ISBN'], train_size=0.8, test_size=0.2, random_state=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qCqI48idFET"
      },
      "outputs": [],
      "source": [
        "cat_variable = ['Book-Author','Publisher']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaRUzVzTdFET"
      },
      "outputs": [],
      "source": [
        "# Frequency Encoding Technique\n",
        "encoder_dict = {}\n",
        "for var in cat_variable:\n",
        "    encoder_dict[var] = (x_train[var].value_counts()/len(x_train)).to_dict()\n",
        "\n",
        "\n",
        "encoder_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RziudTZdFEU"
      },
      "outputs": [],
      "source": [
        "# Replace the categorical value with numeric value\n",
        "for var in cat_variable:\n",
        "    x_train[var] = x_train[var].map(encoder_dict[var])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koRveBLxdFEV"
      },
      "outputs": [],
      "source": [
        "print(x_train.shape)\n",
        "x_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEWgSHIAdFEW"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_df = pd.concat([y_train, x_train], axis=1)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f904h0edFEW"
      },
      "outputs": [],
      "source": [
        "# Identifing unique values in the train df\n",
        "print(\"The total dataset has \", train_df.shape[0],\" values.\")\n",
        "print(\"The dataset has \", train_df['ISBN'].nunique(), \" books with unique values\")\n",
        "print(\"The dataset has \", train_df['User-ID'].nunique(), \" users with unique values\")\n",
        "print(\"The dataset has \", sorted(train_df['Book-Rating'].unique()), \" ratings.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_upWt5YtdFEX"
      },
      "outputs": [],
      "source": [
        "# Group movies by column showing number and mean of rating for each book\n",
        "agg_rating = train_df.groupby('ISBN').agg(rating_count = ('Book-Rating','count'),\n",
        "                                          rating_mean = ('Book-Rating', 'mean')).reset_index()\n",
        "print(agg_rating)\n",
        "agg_rating.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFTZ5caPdFEY"
      },
      "outputs": [],
      "source": [
        "# Filter books with 50+ ratings only\n",
        "popular_books = agg_rating[agg_rating['rating_count']>= 120]\n",
        "print(len(popular_books))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79z5E-B2dFEZ"
      },
      "outputs": [],
      "source": [
        "popular_books.sort_values(by='rating_count', ascending=False).head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nERaFjLTdFEa"
      },
      "outputs": [],
      "source": [
        "popular_books.sort_values(by='rating_count', ascending=False).tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRqKQiy5dFEa"
      },
      "outputs": [],
      "source": [
        "# Checking the relationship between rating count and mean.\n",
        "sns.relplot(x='rating_mean', y='rating_count', data=popular_books)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5BbA8PldFEb"
      },
      "outputs": [],
      "source": [
        "sns.jointplot(x='rating_mean', y='rating_count', data=popular_books) #Better approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPM93EN8dFEc"
      },
      "outputs": [],
      "source": [
        "# mearge the popular books and train dataframe\n",
        "final_train_df = pd.merge(train_df,popular_books, on='ISBN', how='inner')\n",
        "final_train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAOB5556dFEd"
      },
      "outputs": [],
      "source": [
        "final_train_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHF5HJrtdFEe"
      },
      "outputs": [],
      "source": [
        "print(final_train_df.shape)\n",
        "print(final_train_df['User-ID'].nunique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Shjsrvd5dFEe"
      },
      "source": [
        "User item Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66thantldFEf"
      },
      "outputs": [],
      "source": [
        "# User item matrix. Rows = users, column = book , value = rating\n",
        "matrix = final_train_df.pivot_table(index='User-ID', columns='Book-Title', values='Book-Rating')\n",
        "matrix.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6LSQQyXdFEg"
      },
      "outputs": [],
      "source": [
        "matrix_norm = matrix.subtract(matrix.mean(axis=1), axis= 'rows')\n",
        "print(matrix_norm.shape)\n",
        "matrix_norm.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHss5wUCdFEg"
      },
      "outputs": [],
      "source": [
        "matrix_norm.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyEbdynZdFEh"
      },
      "outputs": [],
      "source": [
        "# Pearson correlation similarity\n",
        "user_similarity = matrix_norm.T.corr()\n",
        "user_similarity.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o668QrNdFEi"
      },
      "outputs": [],
      "source": [
        "# Cosine Similarities\n",
        "c_user_similarity = cosine_similarity(matrix_norm.fillna(0))\n",
        "c_user_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnhUXwI1dFEj"
      },
      "outputs": [],
      "source": [
        "# Using User-ID 1 as an example to find similar users\n",
        "pick_user = 75\n",
        "\n",
        "# Remove him from the list\n",
        "user_similarity.drop(index=pick_user, inplace=True)\n",
        "\n",
        "# Take a look at the data\n",
        "user_similarity.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytBaP60bdFEk"
      },
      "source": [
        "Similarity matrix ranges from -1 to 1. with +ve values means same movie preference and -ve values means opposite movie preference\n",
        "n = 10. picking out top 10 most similar users\n",
        "since we are looking for similar interest we will set the threshold to a +ve value 0.3\n",
        "sort the similarity from highest to lowest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN1pf1TsdFEl"
      },
      "outputs": [],
      "source": [
        "# Number of similar users\n",
        "n = 10\n",
        "\n",
        "# User similarity threashold\n",
        "similarity_threashold = 0.3\n",
        "\n",
        "# Get top 10 similar users\n",
        "similar_user = user_similarity[user_similarity[pick_user]>similarity_threashold] [pick_user].sort_values(ascending=False)[:n]\n",
        "\n",
        "print(f\"Similar users for user id {pick_user} are \", similar_user)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWC9yFPmdFEm"
      },
      "source": [
        "Narrowing down the item pool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9ovvDlcdFEm"
      },
      "outputs": [],
      "source": [
        "# Books that picked user has read\n",
        "pick_user_read = matrix_norm[matrix_norm.index == pick_user].dropna(axis=1, how='all')\n",
        "pick_user_read"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0TWpbHLdFEn"
      },
      "outputs": [],
      "source": [
        "# Movies that similar users watched. Remove movies that none of the similar users have watched\n",
        "similar_user_book = matrix_norm[matrix_norm.index.isin(similar_user.index)].dropna(axis=1, how='all')\n",
        "similar_user_book"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9dn9Bx7dFEo"
      },
      "outputs": [],
      "source": [
        "# Remove books watched by target user and keep books similar users read\n",
        "for column in pick_user_read.columns:\n",
        "    if column in similar_user_book.columns:\n",
        "        similar_user_book[column].dropna(inplace=True)\n",
        "\n",
        "similar_user_book"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oubYVIbGdFEp"
      },
      "outputs": [],
      "source": [
        "# Dictionary to store item scores\n",
        "item_scores = {}\n",
        "\n",
        "# For loop to loop through columns/ books\n",
        "for i in similar_user_book.columns:\n",
        "\n",
        "    # Rating for book i\n",
        "    book_rating = similar_user_book[i]\n",
        "\n",
        "    # total score for book\n",
        "    total = 0\n",
        "\n",
        "    # Total number of scores\n",
        "    count = 0\n",
        "\n",
        "    # For loop for similar users through each book\n",
        "    for u in similar_user.index:\n",
        "\n",
        "        # Check for rating in each book by the user\n",
        "        pd.isna(book_rating[u]) == False\n",
        "\n",
        "        # If there is a rating, calculate score for the book\n",
        "        score = similar_user[u] * book_rating[u]\n",
        "\n",
        "        # Add score to the total score for that movie so far\n",
        "        total += score\n",
        "\n",
        "        # Add extra count for that score\n",
        "        count += 1\n",
        "\n",
        "    # Get the avg score for the movie\n",
        "        item_scores[i] = total / count\n",
        "\n",
        "# Convert dictionary to pandas df\n",
        "item_scores = pd.DataFrame(item_scores.items(), columns=['Book','Book-Score'])\n",
        "\n",
        "# Rank in decsending order\n",
        "Ranked_scores = item_scores.sort_values(by='Book-Score', ascending=False)\n",
        "\n",
        "# Select top ten rated books\n",
        "m = 10\n",
        "Ranked_scores.head(m)\n",
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}